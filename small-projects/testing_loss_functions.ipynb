{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNrVffgnCE6lNERztdwjvIJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cudaMBI/pytorch/blob/main/small-projects/testing_loss_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Function Library - PyTorch\n",
        "\n",
        "\n",
        "reference: https://www.kaggle.com/code/bigironsphere/loss-function-library-keras-pytorch"
      ],
      "metadata": {
        "id": "pZV4nyYgmCSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import keras\n",
        "import keras.backend as K"
      ],
      "metadata": {
        "id": "0rQyIshs4aFA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dice Loss"
      ],
      "metadata": {
        "id": "7YO8Fj4rlqCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "        \n",
        "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
        "        inputs = torch.sigmoid(inputs)       \n",
        "        \n",
        "        #flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)    \n",
        "        targets = targets.view(-1)\n",
        "        \n",
        "        intersection = (inputs * targets).sum()                            \n",
        "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
        "        \n",
        "        return 1 - dice\n",
        "\n",
        "x = torch.zeros(3,  28, 28)\n",
        "y = torch.ones(3, 28, 28)\n",
        "dice = DiceLoss()\n",
        "print(dice(x,y))     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoC-SS1Tj5Qa",
        "outputId": "37ebb58f-56b0-4094-dbb4-125a638d3623"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.3332)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BCE-Dice Loss"
      ],
      "metadata": {
        "id": "VyMG0L6Rl3QO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#BCE-Dice Loss\n",
        "class DiceBCELoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceBCELoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "        \n",
        "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
        "        inputs = torch.sigmoid(inputs)       \n",
        "        \n",
        "        #flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        \n",
        "        intersection = (inputs * targets).sum()                            \n",
        "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
        "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
        "        Dice_BCE = BCE + dice_loss\n",
        "        \n",
        "        return Dice_BCE\n",
        "\n",
        "x = torch.zeros(3,  28, 28)\n",
        "y = torch.ones(3, 28, 28)\n",
        "dice = DiceBCELoss()\n",
        "print(dice(x,y))             "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AF2Oq06BlL5K",
        "outputId": "dac2ec0a-5a81-4ed9-d553-a490656b953b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.0264)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Jaccard/Intersection over Union (IoU) Loss\n"
      ],
      "metadata": {
        "id": "AMWUZzrsmypg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#IoU\n",
        "class IoULoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(IoULoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "        \n",
        "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
        "        #inputs = torch.sigmoid(inputs)       \n",
        "        \n",
        "        #flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        \n",
        "        #intersection is equivalent to True Positive count\n",
        "        #union is the mutually inclusive area of all labels & predictions \n",
        "        intersection = (inputs * targets).sum()\n",
        "        total = (inputs + targets).sum()\n",
        "        union = total - intersection \n",
        "        \n",
        "        IoU = (intersection + smooth)/(union + smooth)\n",
        "                \n",
        "        return 1 - IoU\n",
        "\n",
        "x = torch.zeros(3,  28, 28)\n",
        "y = torch.ones(3, 28, 28)\n",
        "dice = IoULoss()\n",
        "print(dice(x,y))                     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBHJQHUFmPmm",
        "outputId": "02df9767-13f3-4dc7-d3f4-f94c98ca1edd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.9996)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Focal Loss\n"
      ],
      "metadata": {
        "id": "LjzwBGADnlA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Focal Loss\n",
        "ALPHA = 0.8\n",
        "GAMMA = 2\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, alpha=ALPHA, gamma=GAMMA, smooth=1):\n",
        "        \n",
        "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
        "        inputs = torch.sigmoid(inputs)       \n",
        "        \n",
        "        #flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        \n",
        "        #first compute binary cross-entropy \n",
        "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
        "        BCE_EXP = torch.exp(-BCE)\n",
        "        focal_loss = alpha * (1-BCE_EXP)**gamma * BCE\n",
        "                       \n",
        "        return focal_loss\n",
        "\n",
        "x = torch.zeros(3,  28, 28)\n",
        "y = torch.ones(3, 28, 28)\n",
        "dice = FocalLoss()\n",
        "print(dice(x,y))        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-yKSzranVyA",
        "outputId": "c8b41cb7-0f30-4c23-ec4a-769d9eb7adc8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1386)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lU-IDx7Gnxjp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}